title: USC-EMO-MRI: An emotional speech production database  
slug: USC-EMO-MRI  
authors: Jangwon Kim, Asterios Toutios, Yoon-Chul Kim, Yinghua Zhu, Sungbok Lee, Shrikanth Narayanan  
date: 2014-05-05  
source: https://sail.usc.edu/span/usc-emo-mri/  
type: speech-database  
languages: english  
tags: emotion, speech-production, MRI, real-time-MRI, english  
open_access: yes  
license: CC  
publications: 
citation: Kim, J., Toutios, A., Lee, S., and Narayanan, S. (2020). Vocal tract shaping of emotional speech. Computer, Speech and Language, 64; Kim, J., Toutios, A., Kim, Y-C., Zhu, Y., Lee, S., & Narayanan, S. (2014). USC-EMO-MRI corpus: An emotional speech production database recorded by real-time magnetic resonance imaging. 10th International Seminar on Speech Production (ISSP), Cologne, Germany, 226-229.  
shortdesc: An emotional speech production database recorded by real-time magnetic resonance imaging.  
summary: USC-EMO-MRI is an emotional speech production database which includes real-time magnetic resonance imaging data with synchronized speech audio from five male and five female actors, each producing a passage and a set of sentences in multiple repetitions, while enacting four different target emotions (neutral, happy, angry, sad). The database includes emotion quality evaluation from at least ten listeners for each speaker's data. The database and companion software tools are freely available to the research community.  
<!--
documentation:
tests:
coverage:
reviews:
-->
