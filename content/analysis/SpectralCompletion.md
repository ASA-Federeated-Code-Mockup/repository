title: Spectral Completion of Paritally Masked Sounds  
slug: spectral-completion  
authors: Josh H. McDermott & Andrew J. Oxenham  
date: 2008-02-15  
source: http://mcdermottlab.mit.edu/spec_comp_demos/spec_comp_page1.html  
type: audio files  
languages: cross-linguistic  
tags: audition, sound-sources, masking, perception  
open_access: yes  
publications: McDermott, J. & Oxenham, A. (2008). Spectral completion of partially masked sounds. Proceedings of the National Academy of Sciences of the United States of America. 105(15): 5939-5944.  
citation: McDermott, J. & Oxenham, A. (2008). Spectral Completion Demo Page. Massachusetts Institute of Technology: McDermott lab. http://mcdermottlab.mit.edu/spec_comp_demos/spec_comp_page1.html  
shortdesc: The auditory system uses the audible portions of an object's spectrum to infer the portions that are likely to have been masked, and that are thus not veridically present in the input to the auditory system.  
summary: Natural environments typically contain multiple sound sources. The sounds from these sources frequently overlap in time and often mask each other. Masking could potentially distort the representation of a sound’s spectrum, altering its timbre and impairing object recognition. Here, we report that the auditory system partially corrects for the effects of masking in such situations, by using the audible, unmasked portions of an object’s spectrum to fill in the inaudible portions. This spectral completion mechanism may help to achieve perceptual constancy and thus aid object recognition in complex auditory scenes.  
