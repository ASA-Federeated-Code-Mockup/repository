title: Model-Matched Sounds  
slug: model-match  
authors: Sam V. Norman-Haignere & Josh H. McDermott  
date: 2018-12-03  
source: http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html  
type: audio files  
languages: cross-linguistic  
tags: audition, sensory, auditory-cortex, neuroscience  
open_access: yes  
publications: Norman-Haignere, S. & McDermott, J. (2018). Neural responses to natural and model-matched stimuli reveal distinct computations in primary and nonprimary auditory cortex. PLOS Biology. https://doi.org/10.1371/journal.pbio.2005127  
citation: Norman-Haignere, S. & McDermott, J. (2018). Stimuli from Model-Matching Experiment. Massachusetts Institute of Technology: McDermott Lab. http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html  
shortdesc: Cochleograms and sound files are shown for example stimuli from the model-matching experiment.  
summary: Here, we propose a simple alternative for testing a sensory model: we synthesize a stimulus that yields the same model response as each of a set of natural stimuli, and test whether the natural and “model-matched” stimuli elicit the same neural responses. We used this approach to test whether a common model of auditory cortex—in which spectrogram-like peripheral input is processed by linear spectrotemporal filters—can explain fMRI responses in humans to natural sounds.  
