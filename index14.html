<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" type="image/x-icon" href="https://www.slrb.net/theme/images/icons/slrb.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/pages/search.html">search</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>

<div class="paginator">
    <a href="/index.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index13.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 14 / 19 &nbsp; 
    <a href="/index15.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index19.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>    
    <br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/NVCL-20.html" rel="bookmark" title="Permalink to The Nijmegen-Venray Confabulation List (NVCL-20)">The Nijmegen-Venray Confabulation List (NVCL-20)</a></h1>
		<h4> The NVCL-20 is an observation scale to measure spontaneous confabulation. This scale's items cover spontaneous confabulation, provoked confabulation, and memory and orientation. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/yvonne-c-m-rensen.html">Yvonne C. M. Rensen</a>,&nbsp;
                                        <a class="url fn" href="/author/joukje-m-oosterman.html">Joukje M. Oosterman</a>,&nbsp;
                                        <a class="url fn" href="/author/jessica-e-van-damme.html">Jessica E. van Damme</a>,&nbsp;
                                        <a class="url fn" href="/author/sonja-i-a-griekspoor.html">Sonja I. A. Griekspoor</a>,&nbsp;
                                        <a class="url fn" href="/author/arie-j-wester.html">Arie J. Wester</a>,&nbsp;
                                        <a class="url fn" href="/author/michael-d-kopelman.html">Michael D. Kopelman</a>,&nbsp;
                                        <a class="url fn" href="/author/roy-p-c-kessels.html">& Roy P. C. Kessels</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-11-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://roykessels.nl/tests-and-software/nvcl-20">https://roykessels.nl/tests-and-software/nvcl-20</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/memory.html">memory</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/neuropsychology.html">neuropsychology</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/HomeBank.html" rel="bookmark" title="Permalink to HomeBank">HomeBank</a></h1>
		<h4> A study through automatic speech recognition of untranscribed daylong recordings in the home and elsewhere. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brian-macwhinney.html">Brian MacWhinney</a>,&nbsp;
                                        <a class="url fn" href="/author/anne-warlaumont.html">Anne Warlaumont</a>,&nbsp;
                                        <a class="url fn" href="/author/mark-vandam.html">Mark VanDam</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-10-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://homebank.talkbank.org/">https://homebank.talkbank.org/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech-recognition.html">speech-recognition</a>,&nbsp; 
                                        <a href="/tag/recordings.html">recordings</a>,&nbsp; 
                                        <a href="/tag/conversational-interaction.html">conversational-interaction</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/DAVID.html" rel="bookmark" title="Permalink to Da Amazing Voice Inflection Device">Da Amazing Voice Inflection Device</a></h1>
		<h4> DAVID (Da Amazing Voice Inflection Device) is a free, real-time voice transformation tool able to “colour” any voice recording with an emotion that wasn’t intended by its speaker. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/marco-liuni.html">Marco Liuni</a>,&nbsp;
                                        <a class="url fn" href="/author/petter-johansson.html">Petter Johansson</a>,&nbsp;
                                        <a class="url fn" href="/author/lars-hall.html">Lars Hall</a>,&nbsp;
                                        <a class="url fn" href="/author/rodrigo-segnini.html">Rodrigo Segnini</a>,&nbsp;
                                        <a class="url fn" href="/author/katsumi-watanabe.html">Katsumi Watanabe</a>,&nbsp;
                                        <a class="url fn" href="/author/daniel-richardson.html">Daniel Richardson</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-09-21 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://cream.ircam.fr/?p=44">http://cream.ircam.fr/?p=44</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/swedish.html">Swedish</a>,&nbsp; 
                                        <a href="/tag/japanese.html">Japanese</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/attentive-tracking.html" rel="bookmark" title="Permalink to Attentive Tracking of Sound Sources">Attentive Tracking of Sound Sources</a></h1>
		<h4> Humans track sound sources through feature space with a movable focus of attention. Attentive tracking aids segregation of similar sound sources. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods-josh-h-mcdermott.html">Kevin J.P. Woods & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-08-31 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/attentive_tracking/index.html">http://mcdermottlab.mit.edu/attentive_tracking/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-source.html">sound-source</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/cogsci.html" rel="bookmark" title="Permalink to CogSci2016">CogSci2016</a></h1>
		<h4> Self-paced reading data on Dutch sentences (Dutch native speakers) and English sentences (Dutch and German native speakers). </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/stefan-l-frank.html">Stefan L. Frank</a>,&nbsp;
                                        <a class="url fn" href="/author/thijs-trompenaars.html">Thijs Trompenaars</a>,&nbsp;
                                        <a class="url fn" href="/author/shravan-vasishth.html">Shravan Vasishth</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-05-06 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2Fcogs.12247&file=cogs12247-sup-0001-DataS1.zip">https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2Fcogs.12247&file=cogs12247-sup-0001-DataS1.zip</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/reading.html">reading</a>,&nbsp; 
                                        <a href="/tag/cross-linguistic.html">cross-linguistic</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/german.html">German</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/USC-CreativeIT.html" rel="bookmark" title="Permalink to USC CreativeIT database of multimodal dyadic interactions">USC CreativeIT database of multimodal dyadic interactions</a></h1>
		<h4> Data from 16 actors, male and female, during their affective dyadic interactions ranging from 2-10 minutes each, and two types of improvised interactions: 2 sentence exercises and paraphrases. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/angeliki-metallinou.html">Angeliki Metallinou</a>,&nbsp;
                                        <a class="url fn" href="/author/zhaojun-yang.html">Zhaojun Yang</a>,&nbsp;
                                        <a class="url fn" href="/author/chi-chun-lee.html">Chi-Chun Lee</a>,&nbsp;
                                        <a class="url fn" href="/author/carlos-busso.html">Carlos Busso</a>,&nbsp;
                                        <a class="url fn" href="/author/sharon-carnicke.html">Sharon Carnicke</a>,&nbsp;
                                        <a class="url fn" href="/author/shrikanth-narayanan.html">Shrikanth Narayanan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-04-17 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sail.usc.edu/CreativeIT/">https://sail.usc.edu/CreativeIT/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/dyadic-interactions.html">dyadic-interactions</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/gestures.html">gestures</a>,&nbsp; 
                                        <a href="/tag/motion-capture.html">motion-capture</a>,&nbsp; 
                                        <a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        <a href="/tag/english.html">english</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CSLB.html" rel="bookmark" title="Permalink to The CSLB concept property norms">The CSLB concept property norms</a></h1>
		<h4> The Centre for Speech, Language and the Brain (CSLB) Concept Property Norms are a publicly-available resource for researchers, including those interested in semantic feature representations of conceptual knowledge. The resource currently provides semantic properties and associated production frequency data for 638 concrete concepts, with data for each concept collected from 30 participants. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/barry-j-devereux.html">Barry J. Devereux</a>,&nbsp;
                                        <a class="url fn" href="/author/lorraine-k-tyler.html">Lorraine K. Tyler</a>,&nbsp;
                                        <a class="url fn" href="/author/jeroen-geertzen.html">Jeroen Geertzen</a>,&nbsp;
                                        <a class="url fn" href="/author/billi-randall.html">Billi Randall</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2014-12-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://csl.psychol.cam.ac.uk/propertynorms/">https://csl.psychol.cam.ac.uk/propertynorms/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/semantics.html">semantics</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/word-norms.html">word-norms</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/USC-TIMIT.html" rel="bookmark" title="Permalink to USC-TIMIT: A database of multimodal speech production data">USC-TIMIT: A database of multimodal speech production data</a></h1>
		<h4> Real-time magnetic resonance imaging and electromagnetic articulography database for speech production research. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/shrikanth-narayanan.html">Shrikanth Narayanan</a>,&nbsp;
                                        <a class="url fn" href="/author/asterios-toutios.html">Asterios Toutios</a>,&nbsp;
                                        <a class="url fn" href="/author/vikram-ramanarayanan.html">Vikram Ramanarayanan</a>,&nbsp;
                                        <a class="url fn" href="/author/adam-lammert.html">Adam Lammert</a>,&nbsp;
                                        <a class="url fn" href="/author/jangwon-kim.html">Jangwon Kim</a>,&nbsp;
                                        <a class="url fn" href="/author/sungbok-lee.html">Sungbok Lee</a>,&nbsp;
                                        <a class="url fn" href="/author/krishna-nayak.html">Krishna Nayak</a>,&nbsp;
                                        <a class="url fn" href="/author/yoon-chul-kim.html">Yoon-Chul Kim</a>,&nbsp;
                                        <a class="url fn" href="/author/yinghua-zhu.html">Yinghua Zhu</a>,&nbsp;
                                        <a class="url fn" href="/author/louis-goldstein.html">Louis Goldstein</a>,&nbsp;
                                        <a class="url fn" href="/author/dani-byrd.html">Dani Byrd</a>,&nbsp;
                                        <a class="url fn" href="/author/erik-bresch.html">Erik Bresch</a>,&nbsp;
                                        <a class="url fn" href="/author/prasanta-ghosh.html">Prasanta Ghosh</a>,&nbsp;
                                        <a class="url fn" href="/author/athanasios-katsamanis.html">Athanasios Katsamanis</a>,&nbsp;
                                        <a class="url fn" href="/author/michael-proctor.html">Michael Proctor</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2014-09-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sail.usc.edu/span/usc-timit/">https://sail.usc.edu/span/usc-timit/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech-production.html">speech-production</a>,&nbsp; 
                                        <a href="/tag/mri.html">MRI</a>,&nbsp; 
                                        <a href="/tag/real-time-mri.html">real-time-MRI</a>,&nbsp; 
                                        <a href="/tag/electromagnetic-articulography.html">electromagnetic-articulography</a>,&nbsp; 
                                        <a href="/tag/timit.html">TIMIT</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CGN.html" rel="bookmark" title="Permalink to Corpus Gesproken Nederlands (The Spoken Dutch Corpus)">Corpus Gesproken Nederlands (The Spoken Dutch Corpus)</a></h1>
		<h4> The Spoken Dutch Corpus (CGN) contains 900 hours (and approximately 3.3 million words) of Dutch and Flemish speech. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wjm-levelt.html">W.J.M. Levelt</a>,&nbsp;
                                        <a class="url fn" href="/author/sg-nooteboom.html">S.G. Nooteboom</a>,&nbsp;
                                        <a class="url fn" href="/author/j-bil.html">J. Bil</a>,&nbsp;
                                        <a class="url fn" href="/author/ge-booij.html">G.E. Booij</a>,&nbsp;
                                        <a class="url fn" href="/author/p-dengis.html">P. Dengis</a>,&nbsp;
                                        <a class="url fn" href="/author/e-dewallef.html">E. DeWallef</a>,&nbsp;
                                        <a class="url fn" href="/author/a-hulk.html">A. Hulk</a>,&nbsp;
                                        <a class="url fn" href="/author/b-krekels.html">B. Krekels</a>,&nbsp;
                                        <a class="url fn" href="/author/c-lucas.html">C. Lucas</a>,&nbsp;
                                        <a class="url fn" href="/author/d-van-compernolle.html">D. Van Compernolle</a>,&nbsp;
                                        <a class="url fn" href="/author/w-vonk.html">W. Vonk</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2014-07-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://ivdnt.org/images/stories/producten/documentatie/cgn_website/doc_English/topics/index.htm">https://ivdnt.org/images/stories/producten/documentatie/cgn_website/doc_English/topics/index.htm</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/phonology.html">phonology</a>,&nbsp; 
                                        <a href="/tag/syntax.html">syntax</a>,&nbsp; 
                                        <a href="/tag/word-frequency.html">word-frequency</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/PhonItalia.html" rel="bookmark" title="Permalink to PhonItalia">PhonItalia</a></h1>
		<h4> PhonItalia is an open access lexical database that provides phonological representations for 120,000 Italian word-forms. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/jeremy-goslin.html">Jeremy Goslin</a>,&nbsp;
                                        <a class="url fn" href="/author/claudia-galuzzi.html">Claudia Galuzzi</a>,&nbsp;
                                        <a class="url fn" href="/author/cristina-romani.html">Cristina Romani</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2014-07-16 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://www.psy.plymouth.ac.uk/research/jgoslin/phonitalia/">http://www.psy.plymouth.ac.uk/research/jgoslin/phonitalia/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/lexicon.html">lexicon</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/database.html">database</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/word-forms.html">word-forms</a>,&nbsp; 
                                        <a href="/tag/italian.html">Italian</a> 
        </div>

        <br>


<div class="paginator">
    <a href="/index.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index13.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 14 / 19 &nbsp; 
    <a href="/index15.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index19.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>
  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>