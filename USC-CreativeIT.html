<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>USC CreativeIT database of multimodal dyadic interactions</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" href="https://slrb.net/theme/images/icons/slrb.svg" type="image/x-icon">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

        <meta name="description" content="For each recording, we provide detailed audiovisual and text information, which consists of the audio and video of both interlocutors, the Motion..." />
	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title"> USC CreativeIT database of multimodal dyadic interactions </h1>
	    
	 <table>
    		<tr>
    			<th>Authors:</th>
    			<td>                                    <a class="url fn" href="/author/angeliki-metallinou.html">Angeliki Metallinou</a>,&nbsp;
                                    <a class="url fn" href="/author/zhaojun-yang.html">Zhaojun Yang</a>,&nbsp;
                                    <a class="url fn" href="/author/chi-chun-lee.html">Chi-Chun Lee</a>,&nbsp;
                                    <a class="url fn" href="/author/carlos-busso.html">Carlos Busso</a>,&nbsp;
                                    <a class="url fn" href="/author/sharon-carnicke.html">Sharon Carnicke</a>,&nbsp;
                                    <a class="url fn" href="/author/shrikanth-narayanan.html">Shrikanth Narayanan</a>
			</td>
    		</tr>
  		<tr>
    			<th>Updated:</th>
    			<td>Fri 17 April 2015</td>
    		</tr>
		<tr>
    			<th>Source:</th>
    			<td><a href="https://sail.usc.edu/CreativeIT/">https://sail.usc.edu/CreativeIT/</a></td>
    		</tr>
		<tr>
    			<th>Type:</th>
    			<td>multimodal-database</td>
    		</tr>
		<tr>
    			<th>Languages:</th>
    			<td>english</td>
    		</tr>
		 <tr>
    			<th>Keywords:</th>
    			<td>	                                        	<a href="/tag/dyadic-interactions.html">dyadic-interactions</a>,&nbsp; 
                                        	<a href="/tag/speech.html">speech</a>,&nbsp; 
                                        	<a href="/tag/gestures.html">gestures</a>,&nbsp; 
                                        	<a href="/tag/motion-capture.html">motion-capture</a>,&nbsp; 
                                        	<a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        	<a href="/tag/english.html">english</a> 
			 </td>
    		</tr>
		<tr>
    			<th>Open Access:</th>
    			<td>yes</td>
    		</tr>
		<tr>
    			<th>License:</th>
    			<td>https://sail.usc.edu/CreativeIT/Data_Release_Form_CreativeIT.pdf</td>
    		</tr>
		<tr>
    			<th>Publications:</th>
    			<td>Metallinou et al. (2016)</td>
    		</tr>
		<tr>
    			<th>Citation:</th>
    			<td>Metallinou, A., Yang, Z., Lee, C-C., Busso, C., Carnicke, S., & Narayanan, S. (2016). The USC CreativeIT database of multimodal dyadic interactions: From speech and full body motion capture to continuous emotional annotations. Language Resources and Evaluation, 50(3), 497-521.</td>
    		</tr>
		<tr>
			<th>Summary:</th>
			<td><p>For each recording, we provide detailed audiovisual and text information, which consists of the audio and video of both interlocutors, the Motion Capture data of the full body of one of the interlocutors in each recording, the text transcriptions of the interaction. Also, for each actor-recording, we provide discrete and time-continuous annotations of dimensional emotion labels, from multiple annotators.</p></td>
	    	</tr>
	</table> 
		
  </article>
</section>
  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>