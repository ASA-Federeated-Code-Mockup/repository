<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - experimentation</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" type="image/x-icon" href="https://www.slrb.net/theme/images/icons/slrb.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/pages/search.html">search</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>

<div class="paginator">
    <a href="/category/experimentation.html"><img src="https://slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/experimentation.html"><img src="https://slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 2 / 3 &nbsp; 
    <a href="/category/experimentation3.html"><img src="https://slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/experimentation3.html"><img src="https://slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>    
    <br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/storybook-apps.html" rel="bookmark" title="Permalink to VL2 Storybook Apps">VL2 Storybook Apps</a></h1>
		<h4> Stories told in sign language by fluent Deaf storytellers. Easy & accessible navigation designed for children. Page-by-page sign language videos supporting the printed sentences text. Rich interactive narrative with direct English to ASL vocabulary video translation. 120+ new vocabulary words with each app. Parents can learn new ASL signs along with their child. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/motion-light-lab.html">Motion Light Lab</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://vl2storybookapps.com/digital-library">https://vl2storybookapps.com/digital-library</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/bilingual.html">bilingual</a>,&nbsp; 
                                        <a href="/tag/american-sign-language.html">American-Sign-Language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/STEP-Experiments.html" rel="bookmark" title="Permalink to System for Teaching Experimental Psychology">System for Teaching Experimental Psychology</a></h1>
		<h4> The goal of STEP was to facilitate the use of E-Prime in various learning contexts. Part of this goal was achieved by creating and hosting a large set of classic experiments implemented in E-Prime. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brian-macwhinney.html">Brian MacWhinney</a>,&nbsp;
                                        <a class="url fn" href="/author/susan-campbell.html">Susan Campbell</a>,&nbsp;
                                        <a class="url fn" href="/author/ping-li.html">Ping Li</a>,&nbsp;
                                        <a class="url fn" href="/author/chris-schunn.html">Chris Schunn</a>,&nbsp;
                                        <a class="url fn" href="/author/and-james-st-james.html">and James St. James</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-23 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments">https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/data-collection.html">data-collection</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/e-prime.html">E-Prime</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/BITTSy.html" rel="bookmark" title="Permalink to BITTSy: Behavioral Infant & Toddler Testing System">BITTSy: Behavioral Infant & Toddler Testing System</a></h1>
		<h4> BITTSy is capable of running key infant behavioral testing paradigms, including Headturn Preference Procedure [HPP], Preferential Looking, and Visual Fixation/Habituation, through the same interface. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/rochelle-newman.html">Rochelle Newman</a>,&nbsp;
                                        <a class="url fn" href="/author/emily-shroads.html">Emily Shroads</a>,&nbsp;
                                        <a class="url fn" href="/author/elizabeth-johnson.html">Elizabeth Johnson</a>,&nbsp;
                                        <a class="url fn" href="/author/ruth-tincoff.html">Ruth Tincoff</a>,&nbsp;
                                        <a class="url fn" href="/author/kris-onishi.html">Kris Onishi</a>,&nbsp;
                                        <a class="url fn" href="/author/giovanna-morini.html">Giovanna Morini</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://langdev.umd.edu/bittsy/">http://langdev.umd.edu/bittsy/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/child-development.html">child-development</a>,&nbsp; 
                                        <a href="/tag/software.html">software</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/IRQ.html" rel="bookmark" title="Permalink to The Internal Representations Questionnaire">The Internal Representations Questionnaire</a></h1>
		<h4> The Internal Representations Questionnaire (IRQ) is a measure designed to quantify the subjective format of thought. There are four factors in the questionnaire namely; visual imagery, propensity to verbalize, representational manipulation and orthographic imagery. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/hettie-roebuck.html">Hettie Roebuck</a>,&nbsp;
                                        <a class="url fn" href="/author/pierce-edmiston.html">Pierce Edmiston</a>,&nbsp;
                                        <a class="url fn" href="/author/gary-lupyan.html">Gary Lupyan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-07-14 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/8rdzh/">https://osf.io/8rdzh/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/cognition.html">cognition</a>,&nbsp; 
                                        <a href="/tag/questionnaire.html">questionnaire</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/headphone-check.html" rel="bookmark" title="Permalink to Headphone Check">Headphone Check</a></h1>
		<h4> This code implements a headphone screening task intended to facilitate web-based experiments employing auditory stimuli. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods.html">Kevin J.P. Woods</a>,&nbsp;
                                        <a class="url fn" href="/author/max-h-siegel.html">Max H. Siegel</a>,&nbsp;
                                        <a class="url fn" href="/author/james-traer.html">James Traer</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/ray-gonzalez.html">Ray Gonzalez</a>,&nbsp;
                                        <a class="url fn" href="/author/kelsey-allen.html">Kelsey Allen</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-02 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/mcdermottLab/HeadphoneCheck">https://github.com/mcdermottLab/HeadphoneCheck</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/stimuli.html">stimuli</a>,&nbsp; 
                                        <a href="/tag/pure-tone.html">pure-tone</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/spatial-orientation.html" rel="bookmark" title="Permalink to Spatial Orientation Test">Spatial Orientation Test</a></h1>
		<h4> On each trial of the SOT, people are shown an array of objects; they have to imagine being located at one object, facing a second object (the orienting cue). They must indicate the direction of a third object (the target object) by drawing a line from the center of the circle in the direction believed to be correct. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/alinda-friedman.html">Alinda Friedman</a>,&nbsp;
                                        <a class="url fn" href="/author/alexander-paul-boone.html">Alexander Paul Boone</a>,&nbsp;
                                        <a class="url fn" href="/author/bernd-kohler.html">Bernd Kohler</a>,&nbsp;
                                        <a class="url fn" href="/author/mary-hegarty.html">Mary Hegarty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-05-26 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/wq3kd/">https://osf.io/wq3kd/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/spatial-ability.html">spatial-ability</a>,&nbsp; 
                                        <a href="/tag/perspective.html">perspective</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CMUSphinx.html" rel="bookmark" title="Permalink to CMUSphinx4">CMUSphinx4</a></h1>
		<h4> CMU Sphinx is a set of speech recognition development libraries and tools that can be linked in to speech-enable applications. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/evandro-gouvea.html">Evandro Gouvea</a>,&nbsp;
                                        <a class="url fn" href="/author/peter-gorniak.html">Peter Gorniak</a>,&nbsp;
                                        <a class="url fn" href="/author/philip-kwok.html">Philip Kwok</a>,&nbsp;
                                        <a class="url fn" href="/author/paul-lamere.html">Paul Lamere</a>,&nbsp;
                                        <a class="url fn" href="/author/beth-logan.html">Beth Logan</a>,&nbsp;
                                        <a class="url fn" href="/author/pedro-moreno.html">Pedro Moreno</a>,&nbsp;
                                        <a class="url fn" href="/author/bhiksha-raj.html">Bhiksha Raj</a>,&nbsp;
                                        <a class="url fn" href="/author/mosur-ravishankar.html">Mosur Ravishankar</a>,&nbsp;
                                        <a class="url fn" href="/author/bent-schmidt-nielsen.html">Bent Schmidt-Nielsen</a>,&nbsp;
                                        <a class="url fn" href="/author/rita-singh.html">Rita Singh</a>,&nbsp;
                                        <a class="url fn" href="/author/jm-van-thong.html">JM Van Thong</a>,&nbsp;
                                        <a class="url fn" href="/author/willie-walker.html">Willie Walker</a>,&nbsp;
                                        <a class="url fn" href="/author/manfred-warmuth.html">Manfred Warmuth</a>,&nbsp;
                                        <a class="url fn" href="/author/joe-woelfel.html">Joe Woelfel</a>,&nbsp;
                                        <a class="url fn" href="/author/peter-wolf.html">Peter Wolf</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-10-23 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://cmusphinx.github.io/">https://cmusphinx.github.io/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a>,&nbsp; 
                                        <a href="/tag/java.html">Java</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a>,&nbsp; 
                                        <a href="/tag/mandarin.html">Mandarin</a>,&nbsp; 
                                        <a href="/tag/german.html">German</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a>,&nbsp; 
                                        <a href="/tag/russian.html">Russian</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/predpsych.html" rel="bookmark" title="Permalink to PredPsych">PredPsych</a></h1>
		<h4> PredPsych is a user-friendly toolbox based on machine learning predictive algorithms. It comprises of multiple functionalities for multivariate analyses of quantitative behavioral data based on machine learning models. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/atesh-koul.html">Atesh Koul</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-07-23 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://CRAN.R-project.org/package=PredPsych ; https://github.com/ateshkoul/PredPsych">https://CRAN.R-project.org/package=PredPsych ; https://github.com/ateshkoul/PredPsych</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/PC-PVT.html" rel="bookmark" title="Permalink to PC-PVT">PC-PVT</a></h1>
		<h4> A freely available system for PC-based simple visual reaction time testing that is analogous to the widely used psychomotor vigilance task (PVT). </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/jaques-reifman.html">Jaques Reifman</a>,&nbsp;
                                        <a class="url fn" href="/author/maxim-y-khitrov.html">Maxim Y. Khitrov</a>,&nbsp;
                                        <a class="url fn" href="/author/sridhar-ramakrishnan.html">Sridhar Ramakrishnan</a>,&nbsp;
                                        <a class="url fn" href="/author/kamal-kumar.html">Kamal Kumar</a>,&nbsp;
                                        <a class="url fn" href="/author/jianbo-liu.html">Jianbo Liu</a>,&nbsp;
                                        <a class="url fn" href="/author/srinivas-laxminarayan.html">Srinivas Laxminarayan</a>,&nbsp;
                                        <a class="url fn" href="/author/david-thorsley.html">David Thorsley</a>,&nbsp;
                                        <a class="url fn" href="/author/srinivasan-rajaraman.html">Srinivasan Rajaraman</a>,&nbsp;
                                        <a class="url fn" href="/author/nancy-j-wesensten.html">Nancy J. Wesensten</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://pcpvt.bhsai.org/pcpvt/register.xhtml">https://pcpvt.bhsai.org/pcpvt/register.xhtml</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/software.html">software</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/pycochleagram.html" rel="bookmark" title="Permalink to Pycochleagram">Pycochleagram</a></h1>
		<h4> Generate cochleagrams natively in Python. Ported from Josh McDermott's MATLAB code. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/ray-gonzalez.html">Ray Gonzalez</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/jenelle-feather.html">Jenelle Feather</a>,&nbsp;
                                        <a class="url fn" href="/author/max-siegel.html">Max Siegel</a>,&nbsp;
                                        <a class="url fn" href="/author/andrew-francl.html">Andrew Francl</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-08-20 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/mcdermottLab/pycochleagram">https://github.com/mcdermottLab/pycochleagram</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/python.html">Python</a>,&nbsp; 
                                        <a href="/tag/matlab.html">MATLAB</a>,&nbsp; 
                                        <a href="/tag/cochleagram.html">cochleagram</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/VAS-RRP.html" rel="bookmark" title="Permalink to The Visual Analogue Scale for Rating, Ranking, and Paired-Comparison Generator">The Visual Analogue Scale for Rating, Ranking, and Paired-Comparison Generator</a></h1>
		<h4> The Visual Analogue Scale for Rating, Ranking, and Paired-Comparison (VAS-RRP) can be used to collect rating, ranking, and paired-comparison data simultaneously. For researchers: You may use the VAS-RRP generator to help you design your own VAS-RRP scale and administer a survey. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/yao-ting-sung-jeng-shin-wu.html">Yao-Ting Sung & Jeng-Shin Wu</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-04-17 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://www.vasrrp.net/">http://www.vasrrp.net/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/data.html">data</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/likert-scales.html">Likert-scales</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/chronset.html" rel="bookmark" title="Permalink to Chronset">Chronset</a></h1>
		<h4> A fully automated tool that estimates speech onset on the basis of multiple acoustic features extracted via multitaper spectral analysis. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/frederic-roux.html">Frédéric Roux</a>,&nbsp;
                                        <a class="url fn" href="/author/blair-c-armstrong.html">Blair C. Armstrong</a>,&nbsp;
                                        <a class="url fn" href="/author/manuel-carreiras.html">Manuel Carreiras</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2017-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.bcbl.eu/databases/chronset/">https://www.bcbl.eu/databases/chronset/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/PATT.html" rel="bookmark" title="Permalink to Phonological Assessment and Treatment Target (PATT) Selection">Phonological Assessment and Treatment Target (PATT) Selection</a></h1>
		<h4> The PATT is a useful protocol for conducting a thorough assessment of a child’s speech in order to strategically select treatment targets based on the child’s presenting sound system, language laws, and treatment efficacy research. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/jessica-barlow.html">Jessica Barlow</a>,&nbsp;
                                        <a class="url fn" href="/author/jennifer-taps-richard.html">Jennifer Taps Richard</a>,&nbsp;
                                        <a class="url fn" href="/author/holly-storkel.html">Holly Storkel</a>,&nbsp;
                                        <a class="url fn" href="/author/philip-combiths.html">Philip Combiths</a>,&nbsp;
                                        <a class="url fn" href="/author/ray-amberg.html">Ray Amberg</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2016-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://cld.lab.uiowa.edu/resources-slps-0/patt-and-autopatt">https://cld.lab.uiowa.edu/resources-slps-0/patt-and-autopatt</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/phonology.html">phonology</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/spanish.html">Spanish</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/AUX.html" rel="bookmark" title="Permalink to AUditory syntaX (AUX)">AUditory syntaX (AUX)</a></h1>
		<h4> AUX (AUditory syntaX) is a scripting syntax specifically designed to describe and process auditory signals. In a nutshell, it consists of 1) functions to create and process sound signals, 2) operators particularly relevant to sounds, and 3) usual mathematic operations that you may find in any programming language. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/bomjun-j-kwon.html">Bomjun J. Kwon</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2016-07-20 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://auditorypro.com/download/aux/">http://auditorypro.com/download/aux/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/psychoacoustic.html">psychoacoustic</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/NVCL-20.html" rel="bookmark" title="Permalink to The Nijmegen-Venray Confabulation List (NVCL-20)">The Nijmegen-Venray Confabulation List (NVCL-20)</a></h1>
		<h4> The NVCL-20 is an observation scale to measure spontaneous confabulation. This scale's items cover spontaneous confabulation, provoked confabulation, and memory and orientation. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/yvonne-c-m-rensen.html">Yvonne C. M. Rensen</a>,&nbsp;
                                        <a class="url fn" href="/author/joukje-m-oosterman.html">Joukje M. Oosterman</a>,&nbsp;
                                        <a class="url fn" href="/author/jessica-e-van-damme.html">Jessica E. van Damme</a>,&nbsp;
                                        <a class="url fn" href="/author/sonja-i-a-griekspoor.html">Sonja I. A. Griekspoor</a>,&nbsp;
                                        <a class="url fn" href="/author/arie-j-wester.html">Arie J. Wester</a>,&nbsp;
                                        <a class="url fn" href="/author/michael-d-kopelman.html">Michael D. Kopelman</a>,&nbsp;
                                        <a class="url fn" href="/author/roy-p-c-kessels.html">& Roy P. C. Kessels</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-11-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://roykessels.nl/tests-and-software/nvcl-20">https://roykessels.nl/tests-and-software/nvcl-20</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/memory.html">memory</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/neuropsychology.html">neuropsychology</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/dutch.html">Dutch</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/jsPsych.html" rel="bookmark" title="Permalink to jsPsych">jsPsych</a></h1>
		<h4> jsPsych is a JavaScript framework for creating behavioral experiments that run in a web browser. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/joshua-de-leeuw.html">Joshua de Leeuw</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.jspsych.org/7.1/">https://www.jspsych.org/7.1/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/data.html">data</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/pitch-localizer.html" rel="bookmark" title="Permalink to Efficient Pitch Localizer">Efficient Pitch Localizer</a></h1>
		<h4> The Efficient Pitch Localizer stimuli are designed to effectively localize pitch regions and to work well with Sensimetrics Earphones. There are two types of stimuli: harmonic tones and frequency-matched gaussian noise. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-norman-haignere.html">Sam Norman-Haignere</a>,&nbsp;
                                        <a class="url fn" href="/author/nancy-kanwisher.html">Nancy Kanwisher</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-mcdermott.html">Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-12-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://web.mit.edu/svnh/www/Resolvability/Efficient_Pitch_Localizer.html">http://web.mit.edu/svnh/www/Resolvability/Efficient_Pitch_Localizer.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/pitch.html">pitch</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/harmonics.html">harmonics</a>,&nbsp; 
                                        <a href="/tag/tonotopy.html">tonotopy</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/POES.html" rel="bookmark" title="Permalink to Program for Open-Ended Scoring">Program for Open-Ended Scoring</a></h1>
		<h4> The Program for Open-Ended Scoring (POES) is a computer program used to score open-ended tests. It was originally designed to score the Levels of Emotional Aareness Scale (LEAS), but it can also be used to score other text material. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/duncan-ermini-leaf-kimberly-a-barchard.html">Duncan Ermini Leaf & Kimberly A. Barchard</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-09-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/deleaf/poes">https://github.com/deleaf/poes</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        <a href="/tag/python.html">Python</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/le-talker.html" rel="bookmark" title="Permalink to LeTalker">LeTalker</a></h1>
		<h4> LeTalker is the name of a Matlab GUI version of the three-mass model of vocal fold vibration originally described in: Story and Titze (1995). LeTalker includes both subglottal and supraglottal (vocal tract) systems. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brad-story.html">Brad Story</a>,&nbsp;
                                        <a class="url fn" href="/author/ingo-titze.html">Ingo Titze</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-08-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sal.arizona.edu/node/10">https://sal.arizona.edu/node/10</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/vocal-tract.html">vocal-tract</a>,&nbsp; 
                                        <a href="/tag/code.html">code</a>,&nbsp; 
                                        <a href="/tag/matlab.html">matlab</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ALEQ.html" rel="bookmark" title="Permalink to Alberta Language Environment Questionnaire">Alberta Language Environment Questionnaire</a></h1>
		<h4> The ALEQ consists of questions about family demographics, language use among family members in the home, and other aspects of an ESL child's language environment. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/johanne-paradis.html">Johanne Paradis</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2011-10-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sites.google.com/ualberta.ca/chesl/questionnaires">https://sites.google.com/ualberta.ca/chesl/questionnaires</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language-development.html">language-development</a>,&nbsp; 
                                        <a href="/tag/environment.html">environment</a>,&nbsp; 
                                        <a href="/tag/language-exposure.html">language-exposure</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/speech-pathology.html">speech-pathology</a>,&nbsp; 
                                        <a href="/tag/multilingual.html">multilingual</a> 
        </div>

        <br>


<div class="paginator">
    <a href="/category/experimentation.html"><img src="https://slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/experimentation.html"><img src="https://slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 2 / 3 &nbsp; 
    <a href="/category/experimentation3.html"><img src="https://slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/experimentation3.html"><img src="https://slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>
  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>