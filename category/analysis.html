<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - analysis</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" type="image/x-icon" href="https://www.slrb.net/theme/images/icons/slrb.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/pages/search.html">search</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>

<div class="paginator">
    <a href="/category/analysis.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 1 / 4 &nbsp; 
    <a href="/category/analysis2.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/analysis4.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>    
    <br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/soundgen.html" rel="bookmark" title="Permalink to Soundgen">Soundgen</a></h1>
		<h4> Soundgen is an open-source toolbox for voice synthesis, manipulation, and analysis. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/andrey-anikin.html">Andrey Anikin</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-11-21 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://CRAN.R-project.org/package=soundgen">https://CRAN.R-project.org/package=soundgen</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-synthesis.html">sound-synthesis</a>,&nbsp; 
                                        <a href="/tag/pitch.html">pitch</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ALICE.html" rel="bookmark" title="Permalink to Automatic Linguistic Unit Count Estimator (ALICE)">Automatic Linguistic Unit Count Estimator (ALICE)</a></h1>
		<h4> ALICE is a tool for estimating the number of adult-spoken linguistic units from child-centered audio recordings, as captured by microphones worn by children. It is meant as an open-source alternative for LENA adult word count (AWC) estimator. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/okko-rasanen.html">Okko Räsänen</a>,&nbsp;
                                        <a class="url fn" href="/author/shreyas-seshadri.html">Shreyas Seshadri</a>,&nbsp;
                                        <a class="url fn" href="/author/marvin-lavechin.html">Marvin Lavechin</a>,&nbsp;
                                        <a class="url fn" href="/author/alejandrina-cristia.html">Alejandrina Cristia</a>,&nbsp;
                                        <a class="url fn" href="/author/marisa-casillas.html">Marisa Casillas</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-11-02 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/orasanen/ALICE">https://github.com/orasanen/ALICE</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/speech-production.html">speech-production</a>,&nbsp; 
                                        <a href="/tag/argentinian-spanish.html">Argentinian Spanish</a>,&nbsp; 
                                        <a href="/tag/tseltal.html">Tseltal</a>,&nbsp; 
                                        <a href="/tag/yeli-dnye.html">Yélî Dnye</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ANLffr.html" rel="bookmark" title="Permalink to ANL Frequency-Following Responses">ANL Frequency-Following Responses</a></h1>
		<h4> A set of tools to analyze and interpret auditory steady-state responses, particularly the subcortical kind commonly known as frequency-following responses (FFRs). </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/hari-bharadwaj.html">Hari Bharadwaj</a>,&nbsp;
                                        <a class="url fn" href="/author/hao-lu.html">Hao Lu</a>,&nbsp;
                                        <a class="url fn" href="/author/lenny-varghese.html">Lenny Varghese</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-04-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/SNAPsoftware/ANLffr">https://github.com/SNAPsoftware/ANLffr</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/python.html">Python</a>,&nbsp; 
                                        <a href="/tag/phase-locking.html">phase-locking</a>,&nbsp; 
                                        <a href="/tag/eeg.html">EEG</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> tested&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/phonetics-jl.html" rel="bookmark" title="Permalink to Phonetics.jl">Phonetics.jl</a></h1>
		<h4> A collection of functions to analyze phonetic data in Julia. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/matthew-c-kelley.html">Matthew C. Kelley</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-02-08 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/maetshju/phonetics.jl">https://github.com/maetshju/phonetics.jl</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/julia.html">julia</a>,&nbsp; 
                                        <a href="/tag/vowels.html">vowels</a>,&nbsp; 
                                        <a href="/tag/plotting.html">plotting</a>,&nbsp; 
                                        <a href="/tag/lexicon.html">lexicon</a>,&nbsp; 
                                        <a href="/tag/acoustic-distance.html">acoustic-distance</a>,&nbsp; 
                                        <a href="/tag/neighborhood-density.html">neighborhood-density</a>,&nbsp; 
                                        <a href="/tag/phonotactic-probability.html">phonotactic-probability</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/NAF.html" rel="bookmark" title="Permalink to Nasalization from Acoustic Features (NAF)">Nasalization from Acoustic Features (NAF)</a></h1>
		<h4> R code implementing a methodology for the automatic measurement of vowel nasalization from acoustic data. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/christopher-carignan.html">Christopher Carignan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-02-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/ChristopherCarignan/NAF/">https://github.com/ChristopherCarignan/NAF/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/nasalization.html">nasalization</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/machine-learning.html">machine-learning</a>,&nbsp; 
                                        <a href="/tag/mfcc.html">MFCC</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/r.html">R</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/SemDis.html" rel="bookmark" title="Permalink to SemDis">SemDis</a></h1>
		<h4> SemDis uses advances in natural language processing to automatically determine how closely associated texts are to each other. Higher SemDis scores indicate two texts are less related, that is, they are more distantly related ideas or concepts. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/dan-johnson-roger-beaty.html">Dan Johnson & Roger Beaty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-10-08 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://semdis.wlu.psu.edu/">http://semdis.wlu.psu.edu/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/semantics.html">semantics</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/auditory-grouping-cues.html" rel="bookmark" title="Permalink to Auditory Grouping Cues">Auditory Grouping Cues</a></h1>
		<h4> Here, we derive auditory grouping cues by measuring and summarizing statistics of natural sound features. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wiktor-mlynarski.html">Wiktor Młynarski</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-12-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/grouping_statistics/index.html">http://mcdermottlab.mit.edu/grouping_statistics/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/illusory-texture.html" rel="bookmark" title="Permalink to Illusory Texture Demos">Illusory Texture Demos</a></h1>
		<h4> Here you will find some sound examples demonstrating the phenomenon of "illusory sound texture." </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/richard-mcwalter-and-josh-mcdermott.html">Richard McWalter and Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-11-08 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/textcont.html">http://mcdermottlab.mit.edu/textcont.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-texture.html">sound-texture</a>,&nbsp; 
                                        <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/music.html">music</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CRIE.html" rel="bookmark" title="Permalink to Chinese Readability Index Explorer (CRIE)">Chinese Readability Index Explorer (CRIE)</a></h1>
		<h4> The Chinese Readability Index Explorer (CRIE) is composed of four subsystems and incorporates 82 multilevel linguistic features. CRIE is able to conduct the major tasks of segmentation, syntactic parsing, and feature extraction. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/yao-ting-sung.html">Yao-Ting Sung</a>,&nbsp;
                                        <a class="url fn" href="/author/tao-hsing-chang.html">Tao-Hsing Chang</a>,&nbsp;
                                        <a class="url fn" href="/author/wei-chun-lin.html">Wei-Chun Lin</a>,&nbsp;
                                        <a class="url fn" href="/author/kuan-sheng-hsieh.html">Kuan-Sheng Hsieh</a>,&nbsp;
                                        <a class="url fn" href="/author/kuo-en-chang.html">Kuo-En Chang</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-10-08 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://www.chinesereadability.net/CRIE/?LANG=CHT">http://www.chinesereadability.net/CRIE/?LANG=CHT</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/syntax.html">syntax</a>,&nbsp; 
                                        <a href="/tag/phonetics.html">phonetics</a>,&nbsp; 
                                        <a href="/tag/machine-learning.html">machine-learning</a>,&nbsp; 
                                        <a href="/tag/chinese.html">Chinese</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/model-match.html" rel="bookmark" title="Permalink to Model-Matched Sounds">Model-Matched Sounds</a></h1>
		<h4> Cochleograms and sound files are shown for example stimuli from the model-matching experiment. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-v-norman-haignere-josh-h-mcdermott.html">Sam V. Norman-Haignere & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-12-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html">http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/auditory-cortex.html">auditory-cortex</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>


<div class="paginator">
    <a href="/category/analysis.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 1 / 4 &nbsp; 
    <a href="/category/analysis2.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/category/analysis4.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>
  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>