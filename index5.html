<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" type="image/x-icon" href="https://www.slrb.net/theme/images/icons/slrb.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

	<link rel="stylesheet" href="https://files.stork-search.net/basic.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/pages/search.html">search</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
		</div>
        </header>
	<br>

<div class="paginator">
    <a href="/index.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index4.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 5 / 17 &nbsp; 
    <a href="/index6.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index17.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>    
    <br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/storybook-apps.html" rel="bookmark" title="Permalink to VL2 Storybook Apps">VL2 Storybook Apps</a></h1>
		<h4> Stories told in sign language by fluent Deaf storytellers. Easy & accessible navigation designed for children. Page-by-page sign language videos supporting the printed sentences text. Rich interactive narrative with direct English to ASL vocabulary video translation. 120+ new vocabulary words with each app. Parents can learn new ASL signs along with their child. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/motion-light-lab.html">Motion Light Lab</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-11-26 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://vl2storybookapps.com/digital-library">https://vl2storybookapps.com/digital-library</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/bilingual.html">bilingual</a>,&nbsp; 
                                        <a href="/tag/american-sign-language.html">American-Sign-Language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/STEP-Experiments.html" rel="bookmark" title="Permalink to System for Teaching Experimental Psychology">System for Teaching Experimental Psychology</a></h1>
		<h4> The goal of STEP was to facilitate the use of E-Prime in various learning contexts. Part of this goal was achieved by creating and hosting a large set of classic experiments implemented in E-Prime. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brian-macwhinney.html">Brian MacWhinney</a>,&nbsp;
                                        <a class="url fn" href="/author/susan-campbell.html">Susan Campbell</a>,&nbsp;
                                        <a class="url fn" href="/author/ping-li.html">Ping Li</a>,&nbsp;
                                        <a class="url fn" href="/author/chris-schunn.html">Chris Schunn</a>,&nbsp;
                                        <a class="url fn" href="/author/and-james-st-james.html">and James St. James</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-23 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments">https://support.pstnet.com/hc/en-us/categories/360003738794-STEP-Experiments</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/data-collection.html">data-collection</a>,&nbsp; 
                                        <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/e-prime.html">E-Prime</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/BITTSy.html" rel="bookmark" title="Permalink to BITTSy: Behavioral Infant & Toddler Testing System">BITTSy: Behavioral Infant & Toddler Testing System</a></h1>
		<h4> BITTSy is capable of running key infant behavioral testing paradigms, including Headturn Preference Procedure [HPP], Preferential Looking, and Visual Fixation/Habituation, through the same interface. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/rochelle-newman.html">Rochelle Newman</a>,&nbsp;
                                        <a class="url fn" href="/author/emily-shroads.html">Emily Shroads</a>,&nbsp;
                                        <a class="url fn" href="/author/elizabeth-johnson.html">Elizabeth Johnson</a>,&nbsp;
                                        <a class="url fn" href="/author/ruth-tincoff.html">Ruth Tincoff</a>,&nbsp;
                                        <a class="url fn" href="/author/kris-onishi.html">Kris Onishi</a>,&nbsp;
                                        <a class="url fn" href="/author/giovanna-morini.html">Giovanna Morini</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-09-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://langdev.umd.edu/bittsy/">http://langdev.umd.edu/bittsy/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/child-development.html">child-development</a>,&nbsp; 
                                        <a href="/tag/software.html">software</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/IRQ.html" rel="bookmark" title="Permalink to The Internal Representations Questionnaire">The Internal Representations Questionnaire</a></h1>
		<h4> The Internal Representations Questionnaire (IRQ) is a measure designed to quantify the subjective format of thought. There are four factors in the questionnaire namely; visual imagery, propensity to verbalize, representational manipulation and orthographic imagery. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/hettie-roebuck.html">Hettie Roebuck</a>,&nbsp;
                                        <a class="url fn" href="/author/pierce-edmiston.html">Pierce Edmiston</a>,&nbsp;
                                        <a class="url fn" href="/author/gary-lupyan.html">Gary Lupyan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-07-14 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/8rdzh/">https://osf.io/8rdzh/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/cognition.html">cognition</a>,&nbsp; 
                                        <a href="/tag/questionnaire.html">questionnaire</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ModelTalker.html" rel="bookmark" title="Permalink to The Model Talker System">The Model Talker System</a></h1>
		<h4> The ModelTalker System converts plain English text to speech. It uses recorded speech (either from a prospective SGD user or from a voice donor chosen by or for the SGD user) to create a unique synthetic voice. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/h-timothy-bunnell.html">H. Timothy Bunnell</a>,&nbsp;
                                        <a class="url fn" href="/author/jason-lilley.html">Jason Lilley</a>,&nbsp;
                                        <a class="url fn" href="/author/matthew-buzzell.html">Matthew Buzzell</a>,&nbsp;
                                        <a class="url fn" href="/author/maxwell-schmid.html">Maxwell Schmid</a>,&nbsp;
                                        <a class="url fn" href="/author/bill-moyers.html">Bill Moyers</a>,&nbsp;
                                        <a class="url fn" href="/author/derek-freer.html">Derek Freer</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-25 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.modeltalker.org/">https://www.modeltalker.org/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/communication.html">communication</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/phonology.html">phonology</a>,&nbsp; 
                                        <a href="/tag/morphology.html">morphology</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/headphone-check.html" rel="bookmark" title="Permalink to Headphone Check">Headphone Check</a></h1>
		<h4> This code implements a headphone screening task intended to facilitate web-based experiments employing auditory stimuli. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods.html">Kevin J.P. Woods</a>,&nbsp;
                                        <a class="url fn" href="/author/max-h-siegel.html">Max H. Siegel</a>,&nbsp;
                                        <a class="url fn" href="/author/james-traer.html">James Traer</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/ray-gonzalez.html">Ray Gonzalez</a>,&nbsp;
                                        <a class="url fn" href="/author/kelsey-allen.html">Kelsey Allen</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-02 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/mcdermottLab/HeadphoneCheck">https://github.com/mcdermottLab/HeadphoneCheck</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/stimuli.html">stimuli</a>,&nbsp; 
                                        <a href="/tag/pure-tone.html">pure-tone</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/spatial-orientation.html" rel="bookmark" title="Permalink to Spatial Orientation Test">Spatial Orientation Test</a></h1>
		<h4> On each trial of the SOT, people are shown an array of objects; they have to imagine being located at one object, facing a second object (the orienting cue). They must indicate the direction of a third object (the target object) by drawing a line from the center of the circle in the direction believed to be correct. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/alinda-friedman.html">Alinda Friedman</a>,&nbsp;
                                        <a class="url fn" href="/author/alexander-paul-boone.html">Alexander Paul Boone</a>,&nbsp;
                                        <a class="url fn" href="/author/bernd-kohler.html">Bernd Kohler</a>,&nbsp;
                                        <a class="url fn" href="/author/mary-hegarty.html">Mary Hegarty</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-05-26 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://osf.io/wq3kd/">https://osf.io/wq3kd/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychology.html">psychology</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/spatial-ability.html">spatial-ability</a>,&nbsp; 
                                        <a href="/tag/perspective.html">perspective</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ECP-L2.html" rel="bookmark" title="Permalink to The English Crowdsourcing Project (L2 speakers)">The English Crowdsourcing Project (L2 speakers)</a></h1>
		<h4> The English Crowdsourcing Project (L2) contains word recognition times for 61,851 English words in a Y/N vocabulary recognition task. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/marc-brysbaert.html">Marc Brysbaert</a>,&nbsp;
                                        <a class="url fn" href="/author/emmanuel-keuleers.html">Emmanuel Keuleers</a>,&nbsp;
                                        <a class="url fn" href="/author/pawel-mandera.html">Pawel Mandera</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-05-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://crr.ugent.be/programs-data/lexicon-projects">http://crr.ugent.be/programs-data/lexicon-projects</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/word-prevalence.html">word-prevalence</a>,&nbsp; 
                                        <a href="/tag/word-frequency.html">word-frequency</a>,&nbsp; 
                                        <a href="/tag/word-knowledge.html">word-knowledge</a>,&nbsp; 
                                        <a href="/tag/crowdsourcing.html">crowdsourcing</a>,&nbsp; 
                                        <a href="/tag/language-acquisition.html">language-acquisition</a>,&nbsp; 
                                        <a href="/tag/vocabulary.html">vocabulary</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/COCA.html" rel="bookmark" title="Permalink to Corpus of Contemporary American English">Corpus of Contemporary American English</a></h1>
		<h4> The Corpus of Contemporary American English (COCA) is the only large, genre-balanced corpus of American English. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/mark-davies.html">Mark Davies</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-03-26 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.english-corpora.org/coca/">https://www.english-corpora.org/coca/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/corpora.html">corpora</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/frequency-data.html">frequency-data</a>,&nbsp; 
                                        <a href="/tag/word-form.html">word-form</a> 
        </div>

        <br>

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ArtLex-en.html" rel="bookmark" title="Permalink to ArtLex-en: Acoustic and EMA data on thousands of words and syllables spoken by a single speaker of American English">ArtLex-en: Acoustic and EMA data on thousands of words and syllables spoken by a single speaker of American English</a></h1>
		<h4> EMA and acoustic data on over 20,000 words and approximately 2,000 controlled syllables spoken in isolation by a single speaker of Midwestern American English. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/charles-redmon.html">Charles Redmon</a>,&nbsp;
                                        <a class="url fn" href="/author/seulgi-shin.html">Seulgi Shin</a>,&nbsp;
                                        <a class="url fn" href="/author/panying-rong.html">Panying Rong</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-03-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://gitlab.com/chredmon/ku-artlex_eng1">https://gitlab.com/chredmon/ku-artlex_eng1</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/electromagnetic-articulography.html">electromagnetic-articulography</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/lexicon.html">lexicon</a>,&nbsp; 
                                        <a href="/tag/english.html">english</a> 
        </div>

        <br>


<div class="paginator">
    <a href="/index.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left-stop.png" alt="|<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index4.html"><img src="https://www.slrb.net/theme/images/icons/arrow-left.png" alt="<" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; Page 5 / 17 &nbsp; 
    <a href="/index6.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right.png" alt=">" style="vertical-align:middle;width:32px;height:32px;"></a>
    &nbsp; 
    <a href="/index17.html"><img src="https://www.slrb.net/theme/images/icons/arrow-right-stop.png" alt=">|" style="vertical-align:middle;width:32px;height:32px;"></a>
</div>
  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

	<script src="https://files.stork-search.net/releases/v1.5.0/stork.js"></script>
	<script>
		stork.register("sitesearch", "/search-index.st")
	</script>
</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>