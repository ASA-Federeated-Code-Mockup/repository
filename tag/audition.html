<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - audition</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" href="https://slrb.net/theme/images/icons/slrb.svg" type="image/x-icon">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
			
  			<input type="text" placeholder="search (coming soon)">
		</div>
        </header>
	<br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/auditory-grouping-cues.html" rel="bookmark" title="Permalink to Auditory Grouping Cues">Auditory Grouping Cues</a></h1>
		<h4> Here, we derive auditory grouping cues by measuring and summarizing statistics of natural sound features. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wiktor-mlynarski.html">Wiktor MÅ‚ynarski</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-12-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/grouping_statistics/index.html">http://mcdermottlab.mit.edu/grouping_statistics/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/model-match.html" rel="bookmark" title="Permalink to Model-Matched Sounds">Model-Matched Sounds</a></h1>
		<h4> Cochleograms and sound files are shown for example stimuli from the model-matching experiment. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-v-norman-haignere-josh-h-mcdermott.html">Sam V. Norman-Haignere & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-12-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html">http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/auditory-cortex.html">auditory-cortex</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/texture-time-averaging.html" rel="bookmark" title="Permalink to Texture-Time Averaging">Texture-Time Averaging</a></h1>
		<h4> Audio files showing the adaptive and selective time-averaging of auditory scenes. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/richard-mcwalter-josh-mcdermott.html">Richard McWalter & Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-05-07 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/textint.html">http://mcdermottlab.mit.edu/textint.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/sensory-input.html">sensory-input</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/schema-learning.html" rel="bookmark" title="Permalink to Schema Learning for the Cocktail Party Problem">Schema Learning for the Cocktail Party Problem</a></h1>
		<h4> The cocktail party problem requires listeners to infer individual sound </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods-josh-h-mcdermott.html">Kevin J.P. Woods & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-04-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/schema_learning/index.html">http://mcdermottlab.mit.edu/schema_learning/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/schema.html">schema</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/reverberation.html" rel="bookmark" title="Permalink to Reverberation">Reverberation</a></h1>
		<h4> A large-scale statistical analysis of real-world acoustics, revealing strong regularities of reverberation in natural scenes. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/james-traer-josh-h-mcdermott.html">James Traer & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2016-11-29 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/Reverb/ReverbSummary.html">http://mcdermottlab.mit.edu/Reverb/ReverbSummary.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound.html">sound</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/periphery.html">periphery</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/pitch-localizer.html" rel="bookmark" title="Permalink to Efficient Pitch Localizer">Efficient Pitch Localizer</a></h1>
		<h4> The Efficient Pitch Localizer stimuli are designed to effectively localize pitch regions and to work well with Sensimetrics Earphones. There are two types of stimuli: harmonic tones and frequency-matched gaussian noise. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-norman-haignere.html">Sam Norman-Haignere</a>,&nbsp;
                                        <a class="url fn" href="/author/nancy-kanwisher.html">Nancy Kanwisher</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-mcdermott.html">Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-12-11 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://web.mit.edu/svnh/www/Resolvability/Efficient_Pitch_Localizer.html">http://web.mit.edu/svnh/www/Resolvability/Efficient_Pitch_Localizer.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/pitch.html">pitch</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/harmonics.html">harmonics</a>,&nbsp; 
                                        <a href="/tag/tonotopy.html">tonotopy</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/texture.html" rel="bookmark" title="Permalink to Auditory Textures">Auditory Textures</a></h1>
		<h4>  </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott-eero-p-simoncelli.html">Josh H. McDermott & Eero P. Simoncelli</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-02-24 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/texture_examples/index.html">http://mcdermottlab.mit.edu/texture_examples/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sound.html">sound</a>,&nbsp; 
                                        <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/french.html">French</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/source-repetition.html" rel="bookmark" title="Permalink to Source Repetition Stimuli">Source Repetition Stimuli</a></h1>
		<h4> We used a simple generative model to synthesize novel sounds with naturalistic properties. We found that such sounds could be segregated and identified if they occurred more than once across different mixtures, even when the same sounds were impossible to segregate in single mixtures. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/david-wrobleski.html">David Wrobleski</a>,&nbsp;
                                        <a class="url fn" href="/author/andrew-j-oxenham.html">Andrew J. Oxenham</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2011-01-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/source_repetition/index.html">http://mcdermottlab.mit.edu/source_repetition/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/cocktail-party.html" rel="bookmark" title="Permalink to Cocktail Party Problem">Cocktail Party Problem</a></h1>
		<h4> . The cocktail party problem is the task of hearing a sound of interest, often a speech signal, in a complex auditory setting. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2009-01-13 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/cocktail_examples/index.html">http://mcdermottlab.mit.edu/cocktail_examples/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/noise.html">noise</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/sound-contour.html" rel="bookmark" title="Permalink to Sound Contour Demos">Sound Contour Demos</a></h1>
		<h4> A study of relative pitch - the relationships between the pitch of successive sounds - to determine whether properties of relative pitch would generalize to other auditory dimensions. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/andriana-j.html">Andriana J.</a>,&nbsp;
                                        <a class="url fn" href="/author/andrew-j-oxenham.html">Andrew J. Oxenham</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2008-05-09 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/sound_contour_demos/sound_contour_demos.html">http://mcdermottlab.mit.edu/sound_contour_demos/sound_contour_demos.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/pitch.html">pitch</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a> 
        </div>
        
        <br>
        
<p class="paginator">
    Page 1 / 2
        <a href="/tag/audition2.html">&raquo;</a>
        <a href="/tag/audition2.html">&#8649;</a>
</p>


  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>