<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - audition</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" href="https://slrb.net/theme/images/icons/slrb.svg" type="image/x-icon">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
			
  			<input type="text" placeholder="search (coming soon)">
		</div>
        </header>
	<br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/headphone-screen.html" rel="bookmark" title="Permalink to Efficient Headphone Screen">Efficient Headphone Screen</a></h1>
		<h4> Conducting online auditory experiments? A new headphone test to help you to efficiently screen out participants who probably aren't using headphones. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/alice-e-milne.html">Alice E. Milne</a>,&nbsp;
                                        <a class="url fn" href="/author/roberta-bianco.html">Roberta Bianco</a>,&nbsp;
                                        <a class="url fn" href="/author/katarina-c-poole.html">Katarina C. Poole</a>,&nbsp;
                                        <a class="url fn" href="/author/sijia-zhao.html">Sijia Zhao</a>,&nbsp;
                                        <a class="url fn" href="/author/andrew-j-oxenham.html">Andrew J. Oxenham</a>,&nbsp;
                                        <a class="url fn" href="/author/alexander-j-billig.html">Alexander J. Billig</a>,&nbsp;
                                        <a class="url fn" href="/author/maria-chait.html">Maria Chait</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-07-28 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://app.gorilla.sc/openmaterials/100917">https://app.gorilla.sc/openmaterials/100917</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/stimuli.html">stimuli</a>,&nbsp; 
                                        <a href="/tag/noise.html">noise</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/ANLffr.html" rel="bookmark" title="Permalink to ANL Frequency-Following Responses">ANL Frequency-Following Responses</a></h1>
		<h4> A set of tools to analyze and interpret auditory steady-state responses, particularly the subcortical kind commonly known as frequency-following responses (FFRs). </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/hari-bharadwaj.html">Hari Bharadwaj</a>,&nbsp;
                                        <a class="url fn" href="/author/hao-lu.html">Hao Lu</a>,&nbsp;
                                        <a class="url fn" href="/author/lenny-varghese.html">Lenny Varghese</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2021-04-04 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/SNAPsoftware/ANLffr">https://github.com/SNAPsoftware/ANLffr</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/python.html">Python</a>,&nbsp; 
                                        <a href="/tag/phase-locking.html">phase-locking</a>,&nbsp; 
                                        <a href="/tag/eeg.html">EEG</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/headphone-check.html" rel="bookmark" title="Permalink to Headphone Check">Headphone Check</a></h1>
		<h4> This code implements a headphone screening task intended to facilitate web-based experiments employing auditory stimuli. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods.html">Kevin J.P. Woods</a>,&nbsp;
                                        <a class="url fn" href="/author/max-h-siegel.html">Max H. Siegel</a>,&nbsp;
                                        <a class="url fn" href="/author/james-traer.html">James Traer</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/ray-gonzalez.html">Ray Gonzalez</a>,&nbsp;
                                        <a class="url fn" href="/author/kelsey-allen.html">Kelsey Allen</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-06-02 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://github.com/mcdermottLab/HeadphoneCheck">https://github.com/mcdermottLab/HeadphoneCheck</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/stimuli.html">stimuli</a>,&nbsp; 
                                        <a href="/tag/pure-tone.html">pure-tone</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/StimuliApp.html" rel="bookmark" title="Permalink to StimuliApp">StimuliApp</a></h1>
		<h4> StimuliApp is a free app designed to create psychophysical tests with precise timing on iOS and iPadOS devices. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/rafael-marin-campos.html">Rafael Marin-Campos</a>,&nbsp;
                                        <a class="url fn" href="/author/joseph-dalmau.html">Joseph Dalmau</a>,&nbsp;
                                        <a class="url fn" href="/author/albert-compte.html">Albert Compte</a>,&nbsp;
                                        <a class="url fn" href="/author/daniel-linares.html">Daniel Linares</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2020-02-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.stimuliapp.com/">https://www.stimuliapp.com/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/psychophysics.html">psychophysics</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/visual-stimulation.html">visual-stimulation</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/auditory-grouping-cues.html" rel="bookmark" title="Permalink to Auditory Grouping Cues">Auditory Grouping Cues</a></h1>
		<h4> Here, we derive auditory grouping cues by measuring and summarizing statistics of natural sound features. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wiktor-mlynarski.html">Wiktor MÅ‚ynarski</a>,&nbsp;
                                        <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2019-12-10 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/grouping_statistics/index.html">http://mcdermottlab.mit.edu/grouping_statistics/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/harmony.html">harmony</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/model-match.html" rel="bookmark" title="Permalink to Model-Matched Sounds">Model-Matched Sounds</a></h1>
		<h4> Cochleograms and sound files are shown for example stimuli from the model-matching experiment. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/sam-v-norman-haignere-josh-h-mcdermott.html">Sam V. Norman-Haignere & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-12-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html">http://mcdermottlab.mit.edu/svnh/model-matching/Stimuli_from_Model-Matching_Experiment.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/auditory-cortex.html">auditory-cortex</a>,&nbsp; 
                                        <a href="/tag/neuroscience.html">neuroscience</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/texture-time-averaging.html" rel="bookmark" title="Permalink to Texture-Time Averaging">Texture-Time Averaging</a></h1>
		<h4> Audio files showing the adaptive and selective time-averaging of auditory scenes. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/richard-mcwalter-josh-mcdermott.html">Richard McWalter & Josh McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-05-07 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/textint.html">http://mcdermottlab.mit.edu/textint.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/perception.html">perception</a>,&nbsp; 
                                        <a href="/tag/sensory-input.html">sensory-input</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/schema-learning.html" rel="bookmark" title="Permalink to Schema Learning for the Cocktail Party Problem">Schema Learning for the Cocktail Party Problem</a></h1>
		<h4> The cocktail party problem requires listeners to infer individual sound </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/kevin-jp-woods-josh-h-mcdermott.html">Kevin J.P. Woods & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2018-04-03 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/schema_learning/index.html">http://mcdermottlab.mit.edu/schema_learning/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/schema.html">schema</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/reverberation.html" rel="bookmark" title="Permalink to Reverberation">Reverberation</a></h1>
		<h4> A large-scale statistical analysis of real-world acoustics, revealing strong regularities of reverberation in natural scenes. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/james-traer-josh-h-mcdermott.html">James Traer & Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2016-11-29 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/Reverb/ReverbSummary.html">http://mcdermottlab.mit.edu/Reverb/ReverbSummary.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sound.html">sound</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/periphery.html">periphery</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/AUX.html" rel="bookmark" title="Permalink to AUditory syntaX (AUX)">AUditory syntaX (AUX)</a></h1>
		<h4> AUX (AUditory syntaX) is a scripting syntax specifically designed to describe and process auditory signals. In a nutshell, it consists of 1) functions to create and process sound signals, 2) operators particularly relevant to sounds, and 3) usual mathematic operations that you may find in any programming language. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/bomjun-j-kwon.html">Bomjun J. Kwon</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2016-07-20 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://auditorypro.com/download/aux/">http://auditorypro.com/download/aux/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/psychoacoustic.html">psychoacoustic</a>,&nbsp; 
                                        <a href="/tag/word-recognition.html">word-recognition</a>,&nbsp; 
                                        <a href="/tag/experiment.html">experiment</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/programming.html">programming</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        
<p class="paginator">
    Page 1 / 2
        <a href="/tag/audition2.html">&raquo;</a>
        <a href="/tag/audition2.html">&#8649;</a>
</p>


  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>