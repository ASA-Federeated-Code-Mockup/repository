<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>SLRB - English</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link rel="icon" href="https://slrb.net/theme/images/icons/slrb.svg" type="image/x-icon">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script>
    		$(function(){
        		$('a').each(function(){
            			if ($(this).prop('href') == window.location.href) {
                			$(this).addClass('active'); $(this).parents('li').addClass('active');
            			}
        		});
    		});
	</script>

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <div><img src="https://www.slrb.net/theme/images/icons/slrb.svg" height="30px"/>&nbsp;&nbsp;&nbsp;<h1>Speech and Language Resource Bank</h1></div>
                <div class="topnav">
                                <a href="/pages/home.html">home</a>
                                <a href="/category/analysis.html">analysis</a>
                                <a href="/category/data.html">data</a>
                                <a href="/category/education.html">education</a>
                                <a href="/category/experimentation.html">experimentation</a>
			
  			<input type="text" placeholder="search (coming soon)">
		</div>
        </header>
	<br>
	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/sensory-systems.html" rel="bookmark" title="Permalink to Sensory Systems - Companion Activities">Sensory Systems - Companion Activities</a></h1>
		<h4> Simple activities and demonstrations to use along with the Sensory Systems apps to enhance the experience of each sense. All use inexpensive or on-hand materials and can be used in a variety of ways. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/university-of-utah-health-sciences-genetic-science-learning-center.html">University of Utah Health Sciences: Genetic Science Learning Center</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2015-02-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://teach.genetics.utah.edu/content/senses/">https://teach.genetics.utah.edu/content/senses/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/sensory.html">sensory</a>,&nbsp; 
                                        <a href="/tag/education.html">education</a>,&nbsp; 
                                        <a href="/tag/hearing.html">hearing</a>,&nbsp; 
                                        <a href="/tag/vision.html">vision</a>,&nbsp; 
                                        <a href="/tag/proprioception.html">proprioception</a>,&nbsp; 
                                        <a href="/tag/touch.html">touch</a>,&nbsp; 
                                        <a href="/tag/taste.html">taste</a>,&nbsp; 
                                        <a href="/tag/smell.html">smell</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/USC-EMO-MRI.html" rel="bookmark" title="Permalink to USC-EMO-MRI: An emotional speech production database">USC-EMO-MRI: An emotional speech production database</a></h1>
		<h4> An emotional speech production database recorded by real-time magnetic resonance imaging. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/jangwon-kim.html">Jangwon Kim</a>,&nbsp;
                                        <a class="url fn" href="/author/asterios-toutios.html">Asterios Toutios</a>,&nbsp;
                                        <a class="url fn" href="/author/yoon-chul-kim.html">Yoon-Chul Kim</a>,&nbsp;
                                        <a class="url fn" href="/author/yinghua-zhu.html">Yinghua Zhu</a>,&nbsp;
                                        <a class="url fn" href="/author/sungbok-lee.html">Sungbok Lee</a>,&nbsp;
                                        <a class="url fn" href="/author/shrikanth-narayanan.html">Shrikanth Narayanan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2014-05-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sail.usc.edu/span/usc-emo-mri/">https://sail.usc.edu/span/usc-emo-mri/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/emotion.html">emotion</a>,&nbsp; 
                                        <a href="/tag/speech-production.html">speech-production</a>,&nbsp; 
                                        <a href="/tag/mri.html">MRI</a>,&nbsp; 
                                        <a href="/tag/real-time-mri.html">real-time-MRI</a>,&nbsp; 
                                        <a href="/tag/english.html">english</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/le-talker.html" rel="bookmark" title="Permalink to LeTalker">LeTalker</a></h1>
		<h4> LeTalker is the name of a Matlab GUI version of the three-mass model of vocal fold vibration originally described in: Story and Titze (1995). LeTalker includes both subglottal and supraglottal (vocal tract) systems. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/brad-story.html">Brad Story</a>,&nbsp;
                                        <a class="url fn" href="/author/ingo-titze.html">Ingo Titze</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-08-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sal.arizona.edu/node/10">https://sal.arizona.edu/node/10</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/vocal-tract.html">vocal-tract</a>,&nbsp; 
                                        <a href="/tag/code.html">code</a>,&nbsp; 
                                        <a href="/tag/matlab.html">matlab</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/mtap.html" rel="bookmark" title="Permalink to The Maryland Tongue Analysis Package">The Maryland Tongue Analysis Package</a></h1>
		<h4> The Maryland Tongue Analysis Package (MTAP), containing EdgeTrak and Surfaces, was developed by the Vocal Tract Visualization Laboratory for use with ultrasound images of the tongue. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/the-vocal-tract-vizualization-laboratory.html">The Vocal Tract Vizualization Laboratory</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-07-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.dental.umaryland.edu/speech/software/">https://www.dental.umaryland.edu/speech/software/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/tongue.html">tongue</a>,&nbsp; 
                                        <a href="/tag/palate.html">palate</a>,&nbsp; 
                                        <a href="/tag/ultrasound.html">ultrasound</a>,&nbsp; 
                                        <a href="/tag/diagrams.html">diagrams</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/wear.html" rel="bookmark" title="Permalink to Warriner English Affective Ratings">Warriner English Affective Ratings</a></h1>
		<h4> We have collected affective norms of valence, arousal, and dominance for 13,915 English words (lemmas). They are a complement of our age-of-acquisition ratings and subtitle word frequencies. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/marc-brysbaert.html">Marc Brysbaert</a>,&nbsp;
                                        <a class="url fn" href="/author/victor-kuperman.html">Victor Kuperman</a>,&nbsp;
                                        <a class="url fn" href="/author/and-amy-warriner.html">and Amy Warriner</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2013-01-05 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://crr.ugent.be/archives/1003">http://crr.ugent.be/archives/1003</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/semantics.html">semantics</a>,&nbsp; 
                                        <a href="/tag/crowdsourcing.html">crowdsourcing</a>,&nbsp; 
                                        <a href="/tag/word-frequency.html">word-frequency</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/emotion.html">emotion</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/BLP.html" rel="bookmark" title="Permalink to British Lexicon Project">British Lexicon Project</a></h1>
		<h4> Database of lexical decision times for approximately 14,000 English words and nonwords responded to by British participants. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/emmanuel-keuleers.html">Emmanuel Keuleers</a>,&nbsp;
                                        <a class="url fn" href="/author/paula-lacey.html">Paula Lacey</a>,&nbsp;
                                        <a class="url fn" href="/author/kathleen-rastle.html">Kathleen Rastle</a>,&nbsp;
                                        <a class="url fn" href="/author/marc-brysbaert.html">Marc Brysbaert</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2012-01-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://crr.ugent.be/blp">http://crr.ugent.be/blp</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/text-database.html">text-database</a>,&nbsp; 
                                        <a href="/tag/lexicon.html">lexicon</a>,&nbsp; 
                                        <a href="/tag/behavioural-perception.html">behavioural-perception</a>,&nbsp; 
                                        <a href="/tag/visual-word-recognition.html">visual-word-recognition</a>,&nbsp; 
                                        <a href="/tag/lexical-decision.html">lexical-decision</a>,&nbsp; 
                                        <a href="/tag/megastudy.html">megastudy</a>,&nbsp; 
                                        <a href="/tag/virtual-experiment.html">virtual-experiment</a>,&nbsp; 
                                        <a href="/tag/english.html">english</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/source-repetition.html" rel="bookmark" title="Permalink to Source Repetition Stimuli">Source Repetition Stimuli</a></h1>
		<h4> We used a simple generative model to synthesize novel sounds with naturalistic properties. We found that such sounds could be segregated and identified if they occurred more than once across different mixtures, even when the same sounds were impossible to segregate in single mixtures. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>,&nbsp;
                                        <a class="url fn" href="/author/david-wrobleski.html">David Wrobleski</a>,&nbsp;
                                        <a class="url fn" href="/author/andrew-j-oxenham.html">Andrew J. Oxenham</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2011-01-18 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/source_repetition/index.html">http://mcdermottlab.mit.edu/source_repetition/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/sound-sources.html">sound-sources</a>,&nbsp; 
                                        <a href="/tag/acoustics.html">acoustics</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/CAN.html" rel="bookmark" title="Permalink to Strathy Corpus of Canadian English">Strathy Corpus of Canadian English</a></h1>
		<h4> The Strathy Corpus of Canadian English is a product of the Strathy Language Unit at Queen's University. The corpus contains 50 million words from more than 1,100 spoken, fiction, magazines, newspapers, and academic texts. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/wc-lougheed.html">W.C. Lougheed</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2010-02-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://www.english-corpora.org/can/">https://www.english-corpora.org/can/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/english.html">English</a>,&nbsp; 
                                        <a href="/tag/linguistics.html">linguistics</a>,&nbsp; 
                                        <a href="/tag/corpora.html">corpora</a>,&nbsp; 
                                        <a href="/tag/language.html">language</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/cocktail-party.html" rel="bookmark" title="Permalink to Cocktail Party Problem">Cocktail Party Problem</a></h1>
		<h4> The cocktail party problem is the task of hearing a sound of interest, often a speech signal, in a complex auditory setting. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/josh-h-mcdermott.html">Josh H. McDermott</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2009-02-01 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="http://mcdermottlab.mit.edu/cocktail_examples/index.html">http://mcdermottlab.mit.edu/cocktail_examples/index.html</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/audition.html">audition</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/noise.html">noise</a>,&nbsp; 
                                        <a href="/tag/frequency.html">frequency</a>,&nbsp; 
                                        <a href="/tag/english.html">English</a> 
        </div>
        
        <br>
        

	<div class="note_header">
			<span class="fa fa-unlock-alt"></span> open&nbsp;&nbsp;
			<span class="fa fa-check-circle"></span> documented&nbsp;&nbsp;
	</div>
        <div class="note">
	        <h1><a href="/IEMOCAP.html" rel="bookmark" title="Permalink to IEMOCAP: The Interactive Emotional Dyadic Motion Capture Database">IEMOCAP: The Interactive Emotional Dyadic Motion Capture Database</a></h1>
		<h4> An acted, multimodal and multispeaker database containing approximately 12 hours of audiovisual data, including video, speech, motion capture of face, text transcriptions. </h4>
                <strong>Authors:</strong>&nbsp;                                          <a class="url fn" href="/author/carlos-busso.html">Carlos Busso</a>,&nbsp;
                                        <a class="url fn" href="/author/murtaza-bulut.html">Murtaza Bulut</a>,&nbsp;
                                        <a class="url fn" href="/author/chi-chun-lee.html">Chi-Chun Lee</a>,&nbsp;
                                        <a class="url fn" href="/author/abe-kazemzadeh.html">Abe Kazemzadeh</a>,&nbsp;
                                        <a class="url fn" href="/author/emily-mower.html">Emily Mower</a>,&nbsp;
                                        <a class="url fn" href="/author/samuel-kim.html">Samuel Kim</a>,&nbsp;
                                        <a class="url fn" href="/author/jeannette-n-chang.html">Jeannette N. Chang</a>,&nbsp;
                                        <a class="url fn" href="/author/sungbok-lee.html">Sungbok Lee</a>,&nbsp;
                                        <a class="url fn" href="/author/shrikanth-narayanan.html">Shrikanth Narayanan</a>
 <br>
                <strong>Updated:</strong>&nbsp; 2008-11-09 <br>
            <!-- <br> -->
		<strong>Source:</strong>&nbsp; <a href="https://sail.usc.edu/iemocap/">https://sail.usc.edu/iemocap/</a><br>
                <strong>Keywords:</strong>&nbsp;                                         <a href="/tag/emotions.html">emotions</a>,&nbsp; 
                                        <a href="/tag/behavior.html">behavior</a>,&nbsp; 
                                        <a href="/tag/speech.html">speech</a>,&nbsp; 
                                        <a href="/tag/gesture.html">gesture</a>,&nbsp; 
                                        <a href="/tag/motion-capture.html">motion-capture</a>,&nbsp; 
                                        <a href="/tag/english.html">english</a> 
        </div>
        
        <br>
        
<p class="paginator">
        <a href="/tag/english.html">&#8647;</a>
        <a href="/tag/english5.html">&laquo;</a>
    Page 6 / 7
        <a href="/tag/english7.html">&raquo;</a>
        <a href="/tag/english7.html">&#8649;</a>
</p>


  
        <footer id="contentinfo" class="body">
                <!-- <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address>

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p> -->
        </footer><!-- /#contentinfo -->

</body>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8XWFESHEMV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());  gtag('config', 'G-8XWFESHEMV');
</script>
  
</html>